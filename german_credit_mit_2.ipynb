{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataiku-Specific Start ###\n",
    "import dataiku\n",
    "from dataiku import pandasutils as pdu\n",
    "from scan import *\n",
    "from prep import *\n",
    "### Dataiku-Specific End ###\n",
    "\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Colab-Specific Start ###\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# from scan import *\n",
    "# from prep import *\n",
    "### Colab-Specific End ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Base Dataset for Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the prepared COMPAS dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataiku-Specific Start ###\n",
    "german_credit_prep = dataiku.Dataset(\"german_credit_prep\")\n",
    "german_prep_df = german_credit_prep.get_dataframe()\n",
    "### Dataiku-Specific End ###\n",
    "\n",
    "### Colab-Specific Start ###\n",
    "# dataset_path = \"drive/MyDrive/IJDI/compas_prep.csv\"\n",
    "# compas_df = pd.read_csv(dataset_path)\n",
    "### Colab-Specific End ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only covariates to prepare for simulating probabilities and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_mit_df = german_prep_df\n",
    "german_mit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify probability and outcomes columns\n",
    "PROBA_CONFUSION_COL = 'proba_lr'\n",
    "PROBA_IJDI_COL = 'proba_rf'\n",
    "OUTCOMES_COL = 'outcomes'\n",
    "FEATURES = ['under_25', 'sex', 'job', 'housing', 'savings', 'checking',\n",
    "            'credit_amt', 'duration', 'purpose']\n",
    "THRESHOLD = 0.5\n",
    "LAMBDA_PARAM = 1\n",
    "pd.options.mode.chained_assignment = None  # suppress warnings on chained assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter for only negative outcomes\n",
    "# negatives_df = german_mit_df.loc[german_mit_df[OUTCOMES_COL] == 0]\n",
    "\n",
    "# # scan with positive direction\n",
    "# current_subset, current_score = run_ijdi_scan(negatives_df, FEATURES, PROBA_CONFUSION_COL, PROBA_IJDI_COL, OUTCOMES_COL,\n",
    "#                                               THRESHOLD, LAMBDA_PARAM)\n",
    "# # summarize_scan(negatives_df, FEATURES, PROBA_COL, OUTCOMES_COL, current_subset, include='all')\\\n",
    "# current_subset, current_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Mitigation Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set lambda vales to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vals = [0, 0.3, 1, 3, 10]\n",
    "# n_iters = 1\n",
    "\n",
    "# specify parameters for generating metrics and IJDI scan\n",
    "proba_confusion_col = 'proba_lr'\n",
    "proba_ijdi_col = 'proba_rf'\n",
    "outcomes_col = 'outcomes'\n",
    "features = ['under_25', 'sex', 'job', 'housing', 'savings', 'checking',\n",
    "            'credit_amt', 'duration', 'purpose']\n",
    "threshold = 'threshold'\n",
    "\n",
    "# define stopping criteria\n",
    "stop_limit = 0\n",
    "max_iters = 5\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # suppress warnings on chained assignment\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement approach for negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for negative or positive outcomes\n",
    "negatives_df = german_mit_df.loc[german_mit_df[outcomes_col] == 0]\n",
    "\n",
    "for lambda_param in lambda_vals: # run IJDI scan for various lambda values\n",
    "\n",
    "    print(\"Lambda =\", lambda_param)\n",
    "\n",
    "    i = 0\n",
    "    ijdi_present = True\n",
    "    # set initial threshold\n",
    "    negatives_df['threshold'] = 0.5\n",
    "\n",
    "    while ijdi_present and i <= max_iters:\n",
    "\n",
    "        i += 1\n",
    "        print(\"Iteration\", i)\n",
    "\n",
    "        # Run Negative or Positive IJDI Scan. Make sure to pass in copy because data may be modified by the function!\n",
    "        current_subset, current_score = run_ijdi_scan(negatives_df.copy(deep=True), features, proba_confusion_col, proba_ijdi_col, outcomes_col,\n",
    "                                                      threshold, lambda_param, constant_threshold=False, verbose=True)\n",
    "\n",
    "        print(\"Score for Negative IJDI-Scan:\", current_score)\n",
    "\n",
    "        # append data\n",
    "        row = [lambda_param, i, current_score, 'negative']\n",
    "        sim_data.append(row)\n",
    "\n",
    "        print(row)\n",
    "\n",
    "        if current_score > stop_limit:\n",
    "\n",
    "            # correct IJDI by setting new threshold for subset\n",
    "            negatives_df['threshold'] = correct_ijdi_subset(negatives_df.copy(deep=True), features,\n",
    "                                                            proba_confusion_col, proba_ijdi_col, outcomes_col,\n",
    "                                                            threshold, lambda_param, current_subset)\n",
    "            print(negatives_df['threshold'])\n",
    "\n",
    "        else:\n",
    "            ijdi_present = False\n",
    "\n",
    "        print(\"\\n----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement approach for Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for negative or positive outcomes\n",
    "positives_df = german_mit_df.loc[german_mit_df[outcomes_col] == 1]\n",
    "\n",
    "for lambda_param in lambda_vals: # run IJDI scan for various lambda values\n",
    "\n",
    "    print(\"Lambda =\", lambda_param)\n",
    "\n",
    "    i = 0\n",
    "    ijdi_present = True\n",
    "    # set initial threshold\n",
    "    positives_df['threshold'] = 0.5\n",
    "\n",
    "    while ijdi_present and i <= 20:\n",
    "\n",
    "        i += 1\n",
    "        print(\"Iteration\", i)\n",
    "\n",
    "        # Run Negative or Positive IJDI Scan. Make sure to pass in copy because data may be modified by the function!\n",
    "        current_subset, current_score = run_ijdi_scan(positives_df.copy(deep=True), features, proba_confusion_col, proba_ijdi_col, outcomes_col,\n",
    "                                                      threshold, lambda_param, constant_threshold=False, verbose=True)\n",
    "\n",
    "        print(\"Score for Positives IJDI-Scan:\", current_score)\n",
    "\n",
    "        # append data\n",
    "        row = [lambda_param, i, current_score, 'positive']\n",
    "        sim_data.append(row)\n",
    "\n",
    "        print(row)\n",
    "\n",
    "        if current_score > stop_limit:\n",
    "\n",
    "            # correct IJDI by setting new threshold for subset\n",
    "            positives_df['threshold'] = correct_ijdi_subset(positives_df.copy(deep=True), features,\n",
    "                                                            proba_confusion_col, proba_ijdi_col, outcomes_col,\n",
    "                                                            threshold, lambda_param, current_subset)\n",
    "            print(positives_df['threshold'])\n",
    "\n",
    "        else:\n",
    "            ijdi_present = False\n",
    "\n",
    "        print(\"\\n----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['lambda', 'iteration', 'score', 'scan_type']\n",
    "mit_result_df = pd.DataFrame(sim_data, columns=columns)\n",
    "mit_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recipe outputs\n",
    "german_credit_mit_2 = dataiku.Dataset(\"german_credit_mit_2\")\n",
    "german_credit_mit_2.write_with_schema(mit_result_df)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_german_credit_mit_2",
  "createdOn": 1660588624420,
  "creationTag": {
   "lastModifiedBy": {
    "login": "admin"
   },
   "lastModifiedOn": 1660588624420,
   "versionNumber": 0
  },
  "creator": "admin",
  "customFields": {},
  "dkuGit": {
   "lastInteraction": 0
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "modifiedBy": "admin",
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
