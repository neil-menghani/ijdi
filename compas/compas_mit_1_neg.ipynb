{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-python36",
      "display_name": "Python (env python36)",
      "language": "python"
    },
    "associatedRecipe": "compute_compas_mitigation_1",
    "dkuGit": {
      "lastInteraction": 0
    },
    "creationTag": {
      "versionNumber": 0,
      "lastModifiedBy": {
        "login": "admin"
      },
      "lastModifiedOn": 1660076294064
    },
    "creator": "admin",
    "createdOn": 1660076294064,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataiku-Specific Start ###\nimport dataiku\nfrom dataiku import pandasutils as pdu\nfrom scan import *\nfrom prep import *\nfrom subset import *\n### Dataiku-Specific End ###\n\nimport pandas as pd, numpy as np"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Colab-Specific Start ###\n# from google.colab import drive\n# drive.mount(\u0027/content/drive\u0027)\n# from scan import *\n# from prep import *\n### Colab-Specific End ###"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Base Dataset for Mitigation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read in the prepared COMPAS dataset as a dataframe."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataiku-Specific Start ###\ncompas_prep \u003d dataiku.Dataset(\"compas_prep\")\ncompas_df \u003d compas_prep.get_dataframe()\n### Dataiku-Specific End ###\n\n### Colab-Specific Start ###\n# dataset_path \u003d \"drive/MyDrive/IJDI/compas_prep.csv\"\n# compas_df \u003d pd.read_csv(dataset_path)\n### Colab-Specific End ###"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "compas_df"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mitigation Thresholds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a) 0.45 threshold for everyone (base case)\nb) 0.5 threshold for Black individuals, 0.45 for everyone else (increased threshold for Black defendants)\nc) 0.45 threshold for Black individuals, 0.4 for everyone else (decreased threshold for non-Black defendants)\nd) 0.5 threshold for Black individuals, 0.4 for everyone else (increased threshold for Black defendants and decreased threshold for non-Black defendants)"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "threshold_labels \u003d [\u0027a\u0027, \u0027b\u0027, \u0027c\u0027, \u0027d\u0027]\nthreshold_settings \u003d {\u0027a\u0027 : (0.45, 0.45),\n                      \u0027b\u0027 : (0.5, 0.45),\n                      \u0027c\u0027 : (0.45, 0.4),\n                      \u0027d\u0027 : (0.5, 0.4)}\nfor label in threshold_labels:\n    setting \u003d threshold_settings[label]\n    compas_df[\u0027threshold_\u0027 + label] \u003d compas_df[\u0027race\u0027].apply(lambda x : setting[0] if x \u003d\u003d \u0027African-American\u0027\n                                                                                    else setting[1])\ncompas_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# specify probability and outcomes columns\nPROBA_COL \u003d \u0027proba_compas\u0027\nOUTCOMES_COL \u003d \u0027outcomes\u0027\nFEATURES \u003d [\u0027sex\u0027, \u0027race\u0027, \u0027under_25\u0027, \u0027charge_degree\u0027, \u0027prior_offenses\u0027]\npd.options.mode.chained_assignment \u003d None  # suppress warnings on chained assignment\n\n# filter for negative and positive outcomes\nnegatives_df \u003d compas_df.loc[compas_df[OUTCOMES_COL] \u003d\u003d 0]\npositives_df \u003d compas_df.loc[compas_df[OUTCOMES_COL] \u003d\u003d 1]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# report FPR and TPR of African-Americans and non African-Americans\nfor label in threshold_labels:\n    negative_metrics_df \u003d generate_metrics(negatives_df, PROBA_COL, OUTCOMES_COL,\n                                           \u0027threshold_\u0027 + label, constant_threshold\u003dFalse)\n    positive_metrics_df \u003d generate_metrics(positives_df, PROBA_COL, OUTCOMES_COL,\n                                           \u0027threshold_\u0027 + label, constant_threshold\u003dFalse)\n    negative_metrics_aa_df \u003d negative_metrics_df.loc[negative_metrics_df[\u0027race\u0027] \u003d\u003d \u0027African-American\u0027]\n    negative_metrics_other_df \u003d negative_metrics_df.loc[negative_metrics_df[\u0027race\u0027] !\u003d \u0027African-American\u0027]\n    positive_metrics_aa_df \u003d positive_metrics_df.loc[positive_metrics_df[\u0027race\u0027] \u003d\u003d \u0027African-American\u0027]\n    positive_metrics_other_df \u003d positive_metrics_df.loc[positive_metrics_df[\u0027race\u0027] !\u003d \u0027African-American\u0027]\n    print(\"FPR of African-Americans\", negative_metrics_aa_df[\u0027positives\u0027].sum() / len(negative_metrics_aa_df))\n    print(\"FPR of non African-Americans\", negative_metrics_other_df[\u0027positives\u0027].sum() / len(negative_metrics_other_df))\n    print(\"TPR of African-Americans\", positive_metrics_aa_df[\u0027positives\u0027].sum() / len(positive_metrics_aa_df))\n    print(\"TPR of non African-Americans\", positive_metrics_other_df[\u0027positives\u0027].sum() / len(positive_metrics_other_df))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mitigation Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set lambda vales to test for each case."
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lambda_vals \u003d [0, 0.3, 1, 3, 10]\nrace_subset \u003d {\u0027race\u0027: [\u0027African-American\u0027]}\nn_iters \u003d 1\n\n# specify parameters for generating metrics and IJDI scan\nproba_confusion_col \u003d \u0027proba_compas\u0027\nproba_ijdi_col \u003d \u0027proba_actual\u0027\noutcomes_col \u003d \u0027outcomes\u0027\nfeatures \u003d [\u0027sex\u0027, \u0027race\u0027, \u0027under_25\u0027, \u0027charge_degree\u0027, \u0027prior_offenses\u0027]\n\npd.options.mode.chained_assignment \u003d None  # suppress warnings on chained assignment\n\n# set random seed\nnp.random.seed(100)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sim_data \u003d []\n\nfor label in threshold_labels:\n\n    setting \u003d threshold_settings[label]\n    threshold \u003d \u0027threshold_\u0027 + label\n    print(\"Thresholds: African-Americans {}, All Other Races {}\".format(setting[0], setting[1]))\n\n    for i in range(n_iters): # run n iterations for each k value\n\n        print(\"Iteration\", i+1, \"of\", n_iters)\n\n        # filter for negative and positive outcomes\n        negatives_df \u003d compas_df.loc[compas_df[OUTCOMES_COL] \u003d\u003d 0]\n        positives_df \u003d compas_df.loc[compas_df[OUTCOMES_COL] \u003d\u003d 1]\n\n        for lambda_param in lambda_vals: # run IJDI scan for various lambda values\n\n            print(\"Lambda \u003d\", lambda_param)\n\n            # Run Negative and Positive IJDI Scan. Make sure to pass in copy because data may be modified by the function!\n            negative_score \u003d score_current_subset_ijdi(negatives_df.copy(deep\u003dTrue), features, proba_confusion_col, proba_ijdi_col, outcomes_col,\n                                                       threshold, lambda_param, race_subset, constant_threshold\u003dFalse, verbose\u003dTrue)\n\n            print(\"Score for Negative IJDI-Scan:\", negative_score)\n\n            positive_score \u003d score_current_subset_ijdi(positives_df.copy(deep\u003dTrue), features, proba_confusion_col, proba_ijdi_col, outcomes_col,\n                                                       threshold, lambda_param, race_subset, constant_threshold\u003dFalse, verbose\u003dTrue)\n\n            print(\"Score Positive IJDI-Scan:\", positive_score)\n\n            # append data\n            negative_row \u003d [setting[0], setting[1], lambda_param, negative_score, \u0027negative\u0027]\n            positive_row \u003d [setting[0], setting[1], lambda_param, positive_score, \u0027positive\u0027]\n            sim_data.append(negative_row)\n            sim_data.append(positive_row)\n\n            print(negative_row)\n            print(positive_row)\n\n            print(\"\\n----------------------------------------------------\\n\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "columns \u003d [\u0027threshold_aa\u0027, \u0027threshold_other\u0027, \u0027lambda\u0027, \u0027score\u0027, \u0027scan_type\u0027]\nmit_result_df \u003d pd.DataFrame(sim_data, columns\u003dcolumns)\nmit_result_df"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataiku-Specific Start ###\ncompas_mit_1 \u003d dataiku.Dataset(\"compas_mit_1\")\ncompas_mit_1.write_with_schema(mit_result_df)\n### Dataiku-Specific End ###\n\n### Colab-Specific Start ###\n# dataset_path \u003d \"drive/MyDrive/IJDI/compas_prep.csv\"\n# compas_prep_df.to_csv(dataset_path)\n### Colab-Specific End ###"
      ],
      "outputs": []
    }
  ]
}